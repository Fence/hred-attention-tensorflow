{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle\n",
    "from collections import OrderedDict\n",
    "import collections\n",
    "from nltk.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# load the data molde\n",
    "input_handle = open('data/bg_session.ctx_ADJ.mdl', 'r')\n",
    "\n",
    "# load the tuple dict and the query dict\n",
    "tuple_dict = cPickle.load(input_handle)\n",
    "query_to_id = cPickle.load(input_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a inverted version of the query to id dict\n",
    "id_to_query =  {v: k for k, v in query_to_id.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "When using enumerate you can only use this ones for the data set, you need to reload the data\n",
    "before you can use emenumerate again\n",
    "\"\"\"\n",
    "def open_data():\n",
    "    val_sessions = open('data/val_session.ctx', 'r')\n",
    "    train_session = open('data/tr_session.ctx', 'r')\n",
    "    return train_session, val_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the keys (tuples with two query id's) of the tuple dict to make a new dict \n",
    "tuple_pairs = tuple_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_dict = collections.defaultdict(dict)\n",
    "\"\"\"\n",
    "make a new dict with key anchor query, as value we have a new dict with keys previous query and \n",
    "their value count \n",
    "\n",
    "dict[anchor_query] = { previous_query: count_value}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "for _tuple in tuple_pairs:\n",
    "    search_dict[_tuple[1]][_tuple[0]] = tuple_dict[_tuple] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Func to print the suggested query id's as strings using the id_to_query map\n",
    "\"\"\"\n",
    "def print_suggestion(suggestions):\n",
    "    for suggest in suggestions:\n",
    "        print id_to_query[suggest[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that makes suggestions for a session\n",
    "\n",
    "Input: session file, *.ctx\n",
    "Output: dict with key:session_idx value: (target_query,anchor_query, session, suggestions)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def make_suggestions(session_file, recent_queries=10,num_suggestions=20):\n",
    "    # make a dict to save all the results\n",
    "    suggestion_dict = {}\n",
    "    \n",
    "    # loop over every session in the *.ctx file\n",
    "    for idx, line in enumerate(session_file):\n",
    "        # queries are tab-separated \n",
    "        session = line.strip().split('\\t')\n",
    "        \n",
    "        # we need 10 context queries and 1 target query, min session lengt has to be 11\n",
    "        if len(session) >= recent_queries+1:\n",
    "            target_query = session[-1] # target query is the last query Qm\n",
    "            anchor_query = session[-2] # Anchor query is the query Qm-1\n",
    "            context = session[:-1] # Qm-1 till Q1 are the context queries\n",
    "            \n",
    "            # find anchor in the background set\n",
    "            if anchor_query in query_to_id:\n",
    "                key =  query_to_id[anchor_query] # the key of the query in the bg-set \n",
    "                # check if target query and anchor query are in the background set\n",
    "                if key in search_dict and target_query in query_to_id:\n",
    "                    \"\"\"\n",
    "                    We could use the search dict to find all the queries that follow the anchor query \n",
    "                    in the bg set, we use this queries as suggestions\n",
    "                    \"\"\"\n",
    "                    suggestions = search_dict[key]\n",
    "                    if len(suggestions) > num_suggestions: # we need at least 20 suggestions \n",
    "                        target_key = query_to_id[target_query] # find the key of the target query\n",
    "                        \n",
    "                        if target_key in suggestions: # check if target query is among the suggestions \n",
    "                            # we have a valid session, now we list all the suggestions and sort them\n",
    "                            list_suggestions = [(key, suggestions[key] )for key in suggestions.keys()]\n",
    "                            sorted_suggestions = sorted(list_suggestions, key=lambda x: x[1])[::-1]\n",
    "                            #take only the top 20 suggestions based on counts \n",
    "                            suggestions = sorted_suggestions[0:num_suggestions]\n",
    "                            # save this in the dict key(idx):(target_query,anchor_query, session, suggestions)\n",
    "                            suggestion_dict[idx] = (target_query,anchor_query, session, suggestions)\n",
    "    return suggestion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_session, val_sessions = open_data() # reload the data\n",
    "\n",
    "# dicts with results\n",
    "suggestion_train = make_suggestions(train_session)\n",
    "suggestion_val = make_suggestions(val_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that returens a feature vector for every suggestion \n",
    "\n",
    "Input: suggestion_dict\n",
    "Output: per session a matrix [17,20] with the feature vectors \n",
    "\"\"\"\n",
    "\n",
    "def make_suggestion_features(suggestion_dict, num_features=17):\n",
    "    for session_key in suggestion_dict.keys():\n",
    "        session_tuple = suggestion_dict[session_key]\n",
    "        target_query = session_tuple[0]\n",
    "        anchor_query = session_tuple[1]\n",
    "        suggestions = suggestions[3]\n",
    "        for idx, suggestion in enumerate(suggestions):\n",
    "            suggestion_id = suggestion[0]\n",
    "             = id_to_query[suggestion_id]\n",
    "            \"\"\"\"\n",
    "            For each candidate suggestion, we count how many times it follows \n",
    "            the anchor query in the background data and add this count as a feature.\n",
    "            \"\"\"\n",
    "            follow_anchor_count = suggestion[1]\n",
    "\n",
    "            \"\"\"\n",
    "            Additionally, we use the frequency of the anchor query in the background data.\n",
    "            \"\"\"\n",
    "            bg_freq = None \n",
    "\n",
    "            \"\"\"\n",
    "            We also add the Levenshtein distance between the anchor and the suggestion.\n",
    "            \"\"\"\n",
    "            levenshtein_distance = edit_distance(anchor_query, query_string)\n",
    "\n",
    "            \"\"\"\n",
    "            The suggestion length (characters and words)\n",
    "            \"\"\"\n",
    "            chars_leng = None # met of zonder spaties?\n",
    "            word_leng = None\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
