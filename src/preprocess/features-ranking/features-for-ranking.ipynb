{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cPickle\n",
    "from collections import OrderedDict\n",
    "import collections\n",
    "from nltk.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# load the data molde\n",
    "input_handle = open('data/bg_session.ctx_ADJ.mdl', 'r')\n",
    "\n",
    "# load the tuple dict and the query dict\n",
    "tuple_dict = cPickle.load(input_handle)\n",
    "query_to_id = cPickle.load(input_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a inverted version of the query to id dict\n",
    "id_to_query =  {v: k for k, v in query_to_id.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "When using enumerate you can only use this ones for the data set, you need to reload the data\n",
    "before you can use emenumerate again\n",
    "\"\"\"\n",
    "def open_data():\n",
    "    val_sessions = open('data/val_session.ctx', 'r')\n",
    "    train_session = open('data/tr_session.ctx', 'r')\n",
    "    bg_session = open('data/bg_session.ctx', 'r')\n",
    "    return train_session, val_sessions, bg_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use the keys (tuples with two query id's) of the tuple dict to make a new dict \n",
    "tuple_pairs = tuple_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_dict = collections.defaultdict(dict)\n",
    "\"\"\"\n",
    "make a new dict with key anchor query, as value we have a new dict with keys previous query and \n",
    "their value count \n",
    "\n",
    "dict[anchor_query] = { previous_query: count_value}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for _tuple in tuple_pairs:\n",
    "    search_dict[_tuple[1]][_tuple[0]] = tuple_dict[_tuple] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Func to print the suggested query id's as strings using the id_to_query map\n",
    "\"\"\"\n",
    "def print_suggestion(suggestions):\n",
    "    for suggest in suggestions:\n",
    "        print id_to_query[suggest[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that makes suggestions for a session\n",
    "\n",
    "Input: session file, *.ctx\n",
    "Output: dict with key:session_idx value: (target_query,anchor_query, session, suggestions)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def make_suggestions(session_file, recent_queries=1,num_suggestions=20):\n",
    "    # make a dict to save all the results\n",
    "    suggestion_dict = {}\n",
    "    \n",
    "    # loop over every session in the *.ctx file\n",
    "    for idx, line in enumerate(session_file):\n",
    "        # queries are tab-separated \n",
    "        session = line.strip().split('\\t')\n",
    "        \n",
    "        \n",
    "        if len(session) >= recent_queries+1:\n",
    "            target_query = session[-1] # target query is the last query Qm\n",
    "            anchor_query = session[-2] # Anchor query is the query Qm-1\n",
    "            context = session[:-1] # Qm-1 till Q1 are the context queries\n",
    "            \n",
    "            # find anchor in the background set\n",
    "            if anchor_query in query_to_id:\n",
    "                key =  query_to_id[anchor_query] # the key of the query in the bg-set \n",
    "                # check if target query and anchor query are in the background set\n",
    "                if key in search_dict and target_query in query_to_id:\n",
    "                    \"\"\"\n",
    "                    We could use the search dict to find all the queries that follow the anchor query \n",
    "                    in the bg set, we use this queries as suggestions\n",
    "                    \"\"\"\n",
    "                    suggestions = search_dict[key]\n",
    "                    if len(suggestions) > num_suggestions: # we need at least 20 suggestions \n",
    "                        target_key = query_to_id[target_query] # find the key of the target query\n",
    "                        \n",
    "                        if target_key in suggestions: # check if target query is among the suggestions \n",
    "                            # we have a valid session, now we list all the suggestions and sort them\n",
    "                            list_suggestions = [(key, suggestions[key] )for key in suggestions.keys()]\n",
    "                            sorted_suggestions = sorted(list_suggestions, key=lambda x: x[1])[::-1]\n",
    "                            #take only the top 20 suggestions based on counts \n",
    "                            suggestions = sorted_suggestions[0:num_suggestions]\n",
    "                            # save this in the dict key(idx):(target_query,anchor_query, session, suggestions)\n",
    "                            suggestion_dict[idx] = (target_query,anchor_query, session, suggestions)\n",
    "    return suggestion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_session, val_sessions, bg_session = open_data() # reload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dicts with results\n",
    "suggestion_train = make_suggestions(train_session)\n",
    "suggestion_val = make_suggestions(val_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO Jorg: we hebben de .ctx file nodig van de bg set:\n",
    "\n",
    "\"\"\"\n",
    "Input: session file with string queries\n",
    "Output: dict with the query frequencies \n",
    "\"\"\"\n",
    "def make_query_frequncies(session_file):\n",
    "    query_freq = {}\n",
    "    total_freq = 0\n",
    "    for num, session in enumerate(session_file):\n",
    "        session = session.strip().split('\\t')\n",
    "        for query in session:\n",
    "            query_freq[query] = query_freq.get(query, 0.) + 1.\n",
    "            total_freq += 1\n",
    "    return query_freq\n",
    "\n",
    "query_freq = make_query_frequncies(bg_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_letter_ngram(sentence, n=3):\n",
    "    \"\"\"\n",
    "    How many n-grams fits in this sentenec \n",
    "    \"\"\"\n",
    "    if len(sentence) < n:\n",
    "        return set(sentence)\n",
    "    local_counts = set()\n",
    "    for k in range(len(sentence.strip()) - n + 1): \n",
    "        local_counts.add(sentence[k:k+n])\n",
    "    return local_counts\n",
    "\n",
    "def matches(ng1, ng2):\n",
    "    \"\"\"\n",
    "    For both n-gram sets how many sim elements they contain\n",
    "    \"\"\"\n",
    "    return len(ng1 & ng2)\n",
    "\n",
    "def n_gram_sim(query1, query2,n=3):\n",
    "    \"\"\"\n",
    "    return n-gram similarity between two queries \n",
    "    \"\"\"\n",
    "    return matches(count_letter_ngram(query1, n), count_letter_ngram(query2, n))\n",
    "\n",
    "def make_n_gram_sim_features(context_queries,suggestion):\n",
    "    \"\"\"\n",
    "    For every suggestion make the n-gram similarity for the context queries (at most 10)\n",
    "    \"\"\"\n",
    "    n_sim = [0] * 10\n",
    "    for idx, context_query in enumerate(context_queries):\n",
    "        n_sim[idx] = n_gram_sim(suggestion, context_query,n=3)\n",
    "        if idx >=10:\n",
    "            \"\"\"\n",
    "            only do this for at most 10 context queries \n",
    "            \"\"\"\n",
    "            break\n",
    "    \n",
    "    return n_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function that returens a feature vector for every suggestion \n",
    "\n",
    "Input: suggestion_dict\n",
    "Output: per session a matrix [17,20] with the feature vectors \n",
    "\"\"\"\n",
    "\n",
    "def make_suggestion_features(suggestion_dict, num_features=17):\n",
    "    for session_key in suggestion_dict.keys():\n",
    "        session_tuple = suggestion_dict[session_key]\n",
    "        target_query = session_tuple[0]\n",
    "        context_queries = session_tuple[2][:-1]\n",
    "        anchor_query = session_tuple[1]\n",
    "        suggestions = session_tuple[3]\n",
    "        for idx, suggestion in enumerate(suggestions):\n",
    "            suggestion_id = suggestion[0]\n",
    "            query_string = id_to_query[suggestion_id]\n",
    "            \"\"\"\"\n",
    "            For each candidate suggestion, we count how many times it follows \n",
    "            the anchor query in the background data and add this count as a feature.\n",
    "            \"\"\"\n",
    "            follow_anchor_count = suggestion[1]\n",
    "\n",
    "            \"\"\"\n",
    "            Additionally, we use the frequency of the anchor query in the background data.\n",
    "            \"\"\"\n",
    "            bg_freq = query_freq[query_string]\n",
    "\n",
    "            \"\"\"\n",
    "            We also add the Levenshtein distance between the anchor and the suggestion.\n",
    "            \"\"\"\n",
    "            levenshtein_distance = edit_distance(anchor_query, query_string)\n",
    "\n",
    "            \"\"\"\n",
    "            The suggestion length (characters and words)\n",
    "            \"\"\"\n",
    "            chars_leng = len(query_string) \n",
    "            word_leng = len(query_string.split())\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            We add 10 features corresponding to the character n-gram similarity \n",
    "            between the suggestion and the 10 most recent queries in the context.\n",
    "            \"\"\"\n",
    "            \n",
    "            n_gram_sim =  make_n_gram_sim_features(context_queries, suggestion)\n",
    "            \n",
    "            \"\"\"\n",
    "            HRED Score\n",
    "            \"\"\"\n",
    "            hred_score = None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-78b9b465fa82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmake_suggestion_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuggestion_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-86-b4f9f9c67887>\u001b[0m in \u001b[0;36mmake_suggestion_features\u001b[0;34m(suggestion_dict, num_features)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mWe\u001b[0m \u001b[0malso\u001b[0m \u001b[0madd\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mLevenshtein\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mthe\u001b[0m \u001b[0manchor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msuggestion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \"\"\"\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mlevenshtein_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medit_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manchor_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \"\"\"\n",
      "\u001b[0;32m/Users/Maurits/anaconda/lib/python2.7/site-packages/nltk/metrics/distance.pyc\u001b[0m in \u001b[0;36medit_distance\u001b[0;34m(s1, s2, transpositions)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0m_edit_dist_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspositions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtranspositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Maurits/anaconda/lib/python2.7/site-packages/nltk/metrics/distance.pyc\u001b[0m in \u001b[0;36m_edit_dist_step\u001b[0;34m(lev, i, j, s1, s2, transpositions)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_edit_dist_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspositions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# skipping a character in s1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "make_suggestion_features(suggestion_train, num_features=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
